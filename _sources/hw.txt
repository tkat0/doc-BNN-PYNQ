ハードウェア概要
==============

BNN-PYNQのアクセラレータの概要を記載する

* BNN-PYNQのアクセラレータは、C++のコードからVivado HLSで高位合成で生成
* 学習済みの重みは、全てon-chip（モデルの初期化時にロードする）
* アクセラレータへの入出力データはストリーム処理(AXI4-Stream)
    * DRAMとの接続、レイヤー間の接続は全て64bit幅のストリーム
    * 各レイヤの入出力のI/FはAXI4-Stream
* Binarized Neural NetworkをFPGA最適化するために、計算をビット演算等で近似している
* アクセラレータのコアは、行列xベクトルを計算するMVTUというユニット
    * Fully ConnectedレイヤーもConvolutionレイヤーも、内部ではMVTUを使う
    * レイヤー毎に最適化されたMVTUを持つ
        * MTVUは、内部に複数のPE（Processing Element）をもつ
        * PEは、ビット演算を並列化できる（SIMD）
        * MVTUは、PEの数とPE内の並列度（SIMD幅）を高位合成時に変更できる
            * レイヤー毎に最適化することで、モデル全体のボトルネックをなくしてレイテンシを少なくする
* Folding
    * 完全に並列化するのが理想だが、FPGAのリソースには制限がある
    * そのため、リソース内で最大のハードウェアを用意して、使いまわす仕組み
